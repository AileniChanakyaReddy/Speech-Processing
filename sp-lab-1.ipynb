{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1942970,"sourceType":"datasetVersion","datasetId":1159053}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import wavfile\nimport os\n\nwav_file_path = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/LJ001-0001.wav\"\n\nsample_rate, data = wavfile.read(wav_file_path)\n\nnum_samples = len(data)\nduration = num_samples / sample_rate\n\nprint(f\"Sample Rate: {sample_rate} Hz\")\nprint(f\"Number of Samples: {num_samples}\")\nprint(f\"Duration: {duration:.2f} seconds\")\n\nplt.figure(figsize=(12, 4))\ntime_axis = np.linspace(0, duration, num_samples)\nplt.plot(time_axis, data, label=\"Speech Signal\", color=\"blue\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Waveform of Speech Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:28:45.860115Z","iopub.execute_input":"2025-02-07T08:28:45.860503Z","iopub.status.idle":"2025-02-07T08:28:46.318500Z","shell.execute_reply.started":"2025-02-07T08:28:45.860473Z","shell.execute_reply":"2025-02-07T08:28:46.317428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import wavfile\nimport os\nfrom scipy.signal import resample\n\nwav_file_path = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/LJ001-0001.wav\" \nsample_rate, data = wavfile.read(wav_file_path)\n\n# Get file details\nnum_samples = len(data)\nduration = num_samples / sample_rate\n\n# Slicing: Extract first 2 seconds\nsliced_data = data[:int(2 * sample_rate)]\n\n# Normalization\nnormalized_data = sliced_data / np.max(np.abs(sliced_data))\n\n# Plot sliced signal\nplt.figure(figsize=(12, 4))\ntime_axis = np.linspace(0, 2, len(sliced_data))\nplt.plot(time_axis, sliced_data, label=\"Sliced Signal\", color=\"green\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Sliced Speech Signal (First 2 sec)\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Plot normalized signal\nplt.figure(figsize=(12, 4))\nplt.plot(time_axis, normalized_data, label=\"Normalized Signal\", color=\"red\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Normalized Speech Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Amplification & De-amplification\namplified_data = sliced_data * 2\ndeamplified_data = sliced_data * 0.5\n\n# Plot amplified signal\nplt.figure(figsize=(12, 4))\nplt.plot(time_axis, amplified_data, label=\"Amplified Signal\", color=\"purple\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Amplified Speech Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Plot de-amplified signal\nplt.figure(figsize=(12, 4))\nplt.plot(time_axis, deamplified_data, label=\"De-amplified Signal\", color=\"orange\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"De-amplified Speech Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Up-sampling (increase sample rate by factor of 2)\nupsampled_data = resample(sliced_data, len(sliced_data) * 2)\n\n# Down-sampling (decrease sample rate by factor of 2)\ndownsampled_data = resample(sliced_data, len(sliced_data) // 2)\n\n# Plot up-sampled signal\nplt.figure(figsize=(12, 4))\ntime_axis_upsampled = np.linspace(0, 2, len(upsampled_data))\nplt.plot(time_axis_upsampled, upsampled_data, label=\"Up-sampled Signal\", color=\"cyan\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Up-sampled Speech Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Plot down-sampled signal\nplt.figure(figsize=(12, 4))\ntime_axis_downsampled = np.linspace(0, 2, len(downsampled_data))\nplt.plot(time_axis_downsampled, downsampled_data, label=\"Down-sampled Signal\", color=\"brown\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Down-sampled Speech Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:32:06.835488Z","iopub.execute_input":"2025-02-07T08:32:06.835938Z","iopub.status.idle":"2025-02-07T08:32:08.747601Z","shell.execute_reply.started":"2025-02-07T08:32:06.835905Z","shell.execute_reply":"2025-02-07T08:32:08.746448Z"}},"outputs":[],"execution_count":null}]}